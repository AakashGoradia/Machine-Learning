{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5337fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple Linear Regression\n",
    "\n",
    "#if we include both dummy variables, we would be duplicating.\n",
    "#p-values\n",
    "#building a model strp by step\n",
    "#eliminating useless variables\n",
    "\n",
    "################################\n",
    "#5 Methods for building models\n",
    "\n",
    "#(1) All-in : Throw in all your variables, prior knowledge or you have to use them.\n",
    "\n",
    "#(2) Backward Elimination : (fastest)\n",
    "#   step 1 - select significance level value.(5%)\n",
    "#   step 2 - fitting the full model with all possible predictors, put all variables.\n",
    "#   step 3 - consider the predictor with highest p-value,p is > significance level.\n",
    "#   step 4 - remove the predictor with p value < significance value.\n",
    "#   step 5 - fit the updated model.\n",
    "#Model is Ready\n",
    "\n",
    "#(3) Forward Selection :\n",
    "#   step 1 - select significance level value.(5%)\n",
    "#   step 2 - build regression model with every single variable y-xn, and select those with lowest p-value.\n",
    "#   step 3 - consider the predictor with highest p-value,p is > significance level.\n",
    "#   step 4 - keep this choosen variable and add all other variables(predictor) one by one and construct all possible 2 variable linear regressions.\n",
    "#   step 5 - consider the regression whose newly added predictor has lowest p-value and go to step 3 and keep doing that and grow your model by 1 variable each time.\n",
    "#   step 6 - when p > significance level, end the regression.\n",
    "#Model is Ready\n",
    "\n",
    "#(4) Bidirectional Elimination : \n",
    "#   step 1 - select significance level value.(5%)\n",
    "#   step 2 - build regression model with every single variable y-xn, and select those with lowest p-value. (forward selection)\n",
    "#   step 3 - perform all steps of backward elimination by eliminating variables by going to step 2 again and again.\n",
    "#   step 4 - no new variables can enter and no old variables can exit.\n",
    "#Model is Ready\n",
    "\n",
    "#(5) All possible models / Score Comparison: (resource consuming approach)\n",
    "#   step 1 - select the criterion of goodness of fit (eg: Akaike criterion).\n",
    "#   step 2 - construct all possible regression models, 2^n - 1 combinations.\n",
    "#   step 3 - select the model with the best criterion.\n",
    "#Model is Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45e21f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backward Elimination\n",
    "\n",
    "#STEP 1 - Data Pre-processing\n",
    "\n",
    "#importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a690c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset\n",
    "dataset = pd.read_csv(r\"C:\\Users\\aakas\\OneDrive\\Desktop\\AAKASH GORADIA\\AAKASH GORADIA'S DRIVE\\CAREER\\COURSES\\A-Z Machine Learning\\MyNotebooks\\Machine-Learning\\Part2 - Regression\\Multiple Linear Regression\\50_Startups.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc12d358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>New York</td>\n",
       "      <td>156991.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>California</td>\n",
       "      <td>156122.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>Florida</td>\n",
       "      <td>155752.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>New York</td>\n",
       "      <td>152211.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>California</td>\n",
       "      <td>149759.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>Florida</td>\n",
       "      <td>146121.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>California</td>\n",
       "      <td>144259.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>Florida</td>\n",
       "      <td>141585.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>California</td>\n",
       "      <td>134307.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>Florida</td>\n",
       "      <td>132602.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>New York</td>\n",
       "      <td>129917.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>California</td>\n",
       "      <td>126992.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>New York</td>\n",
       "      <td>125370.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>Florida</td>\n",
       "      <td>124266.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>New York</td>\n",
       "      <td>122776.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>California</td>\n",
       "      <td>118474.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>New York</td>\n",
       "      <td>111313.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>Florida</td>\n",
       "      <td>110352.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>Florida</td>\n",
       "      <td>108733.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>New York</td>\n",
       "      <td>108552.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>California</td>\n",
       "      <td>107404.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>Florida</td>\n",
       "      <td>105733.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>New York</td>\n",
       "      <td>105008.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>Florida</td>\n",
       "      <td>103282.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>New York</td>\n",
       "      <td>101004.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>Florida</td>\n",
       "      <td>99937.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>New York</td>\n",
       "      <td>97483.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>California</td>\n",
       "      <td>97427.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>Florida</td>\n",
       "      <td>96778.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>California</td>\n",
       "      <td>96712.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>New York</td>\n",
       "      <td>96479.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>Florida</td>\n",
       "      <td>90708.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>California</td>\n",
       "      <td>89949.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>81229.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>California</td>\n",
       "      <td>81005.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>California</td>\n",
       "      <td>78239.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>Florida</td>\n",
       "      <td>77798.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>California</td>\n",
       "      <td>71498.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>New York</td>\n",
       "      <td>69758.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>California</td>\n",
       "      <td>65200.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>New York</td>\n",
       "      <td>64926.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>Florida</td>\n",
       "      <td>49490.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>California</td>\n",
       "      <td>42559.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>New York</td>\n",
       "      <td>35673.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>California</td>\n",
       "      <td>14681.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0   165349.20       136897.80        471784.10    New York  192261.83\n",
       "1   162597.70       151377.59        443898.53  California  191792.06\n",
       "2   153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3   144372.41       118671.85        383199.62    New York  182901.99\n",
       "4   142107.34        91391.77        366168.42     Florida  166187.94\n",
       "5   131876.90        99814.71        362861.36    New York  156991.12\n",
       "6   134615.46       147198.87        127716.82  California  156122.51\n",
       "7   130298.13       145530.06        323876.68     Florida  155752.60\n",
       "8   120542.52       148718.95        311613.29    New York  152211.77\n",
       "9   123334.88       108679.17        304981.62  California  149759.96\n",
       "10  101913.08       110594.11        229160.95     Florida  146121.95\n",
       "11  100671.96        91790.61        249744.55  California  144259.40\n",
       "12   93863.75       127320.38        249839.44     Florida  141585.52\n",
       "13   91992.39       135495.07        252664.93  California  134307.35\n",
       "14  119943.24       156547.42        256512.92     Florida  132602.65\n",
       "15  114523.61       122616.84        261776.23    New York  129917.04\n",
       "16   78013.11       121597.55        264346.06  California  126992.93\n",
       "17   94657.16       145077.58        282574.31    New York  125370.37\n",
       "18   91749.16       114175.79        294919.57     Florida  124266.90\n",
       "19   86419.70       153514.11             0.00    New York  122776.86\n",
       "20   76253.86       113867.30        298664.47  California  118474.03\n",
       "21   78389.47       153773.43        299737.29    New York  111313.02\n",
       "22   73994.56       122782.75        303319.26     Florida  110352.25\n",
       "23   67532.53       105751.03        304768.73     Florida  108733.99\n",
       "24   77044.01        99281.34        140574.81    New York  108552.04\n",
       "25   64664.71       139553.16        137962.62  California  107404.34\n",
       "26   75328.87       144135.98        134050.07     Florida  105733.54\n",
       "27   72107.60       127864.55        353183.81    New York  105008.31\n",
       "28   66051.52       182645.56        118148.20     Florida  103282.38\n",
       "29   65605.48       153032.06        107138.38    New York  101004.64\n",
       "30   61994.48       115641.28         91131.24     Florida   99937.59\n",
       "31   61136.38       152701.92         88218.23    New York   97483.56\n",
       "32   63408.86       129219.61         46085.25  California   97427.84\n",
       "33   55493.95       103057.49        214634.81     Florida   96778.92\n",
       "34   46426.07       157693.92        210797.67  California   96712.80\n",
       "35   46014.02        85047.44        205517.64    New York   96479.51\n",
       "36   28663.76       127056.21        201126.82     Florida   90708.19\n",
       "37   44069.95        51283.14        197029.42  California   89949.14\n",
       "38   20229.59        65947.93        185265.10    New York   81229.06\n",
       "39   38558.51        82982.09        174999.30  California   81005.76\n",
       "40   28754.33       118546.05        172795.67  California   78239.91\n",
       "41   27892.92        84710.77        164470.71     Florida   77798.83\n",
       "42   23640.93        96189.63        148001.11  California   71498.49\n",
       "43   15505.73       127382.30         35534.17    New York   69758.98\n",
       "44   22177.74       154806.14         28334.72  California   65200.33\n",
       "45    1000.23       124153.04          1903.93    New York   64926.08\n",
       "46    1315.46       115816.21        297114.46     Florida   49490.75\n",
       "47       0.00       135426.92             0.00  California   42559.73\n",
       "48     542.05        51743.15             0.00    New York   35673.41\n",
       "49       0.00       116983.80         45173.06  California   14681.40"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f95f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#independent variable matrix\n",
    "X = dataset.iloc[:, :4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6241a517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[165349.2, 136897.8, 471784.1, 'New York'],\n",
       "       [162597.7, 151377.59, 443898.53, 'California'],\n",
       "       [153441.51, 101145.55, 407934.54, 'Florida'],\n",
       "       [144372.41, 118671.85, 383199.62, 'New York'],\n",
       "       [142107.34, 91391.77, 366168.42, 'Florida'],\n",
       "       [131876.9, 99814.71, 362861.36, 'New York'],\n",
       "       [134615.46, 147198.87, 127716.82, 'California'],\n",
       "       [130298.13, 145530.06, 323876.68, 'Florida'],\n",
       "       [120542.52, 148718.95, 311613.29, 'New York'],\n",
       "       [123334.88, 108679.17, 304981.62, 'California'],\n",
       "       [101913.08, 110594.11, 229160.95, 'Florida'],\n",
       "       [100671.96, 91790.61, 249744.55, 'California'],\n",
       "       [93863.75, 127320.38, 249839.44, 'Florida'],\n",
       "       [91992.39, 135495.07, 252664.93, 'California'],\n",
       "       [119943.24, 156547.42, 256512.92, 'Florida'],\n",
       "       [114523.61, 122616.84, 261776.23, 'New York'],\n",
       "       [78013.11, 121597.55, 264346.06, 'California'],\n",
       "       [94657.16, 145077.58, 282574.31, 'New York'],\n",
       "       [91749.16, 114175.79, 294919.57, 'Florida'],\n",
       "       [86419.7, 153514.11, 0.0, 'New York'],\n",
       "       [76253.86, 113867.3, 298664.47, 'California'],\n",
       "       [78389.47, 153773.43, 299737.29, 'New York'],\n",
       "       [73994.56, 122782.75, 303319.26, 'Florida'],\n",
       "       [67532.53, 105751.03, 304768.73, 'Florida'],\n",
       "       [77044.01, 99281.34, 140574.81, 'New York'],\n",
       "       [64664.71, 139553.16, 137962.62, 'California'],\n",
       "       [75328.87, 144135.98, 134050.07, 'Florida'],\n",
       "       [72107.6, 127864.55, 353183.81, 'New York'],\n",
       "       [66051.52, 182645.56, 118148.2, 'Florida'],\n",
       "       [65605.48, 153032.06, 107138.38, 'New York'],\n",
       "       [61994.48, 115641.28, 91131.24, 'Florida'],\n",
       "       [61136.38, 152701.92, 88218.23, 'New York'],\n",
       "       [63408.86, 129219.61, 46085.25, 'California'],\n",
       "       [55493.95, 103057.49, 214634.81, 'Florida'],\n",
       "       [46426.07, 157693.92, 210797.67, 'California'],\n",
       "       [46014.02, 85047.44, 205517.64, 'New York'],\n",
       "       [28663.76, 127056.21, 201126.82, 'Florida'],\n",
       "       [44069.95, 51283.14, 197029.42, 'California'],\n",
       "       [20229.59, 65947.93, 185265.1, 'New York'],\n",
       "       [38558.51, 82982.09, 174999.3, 'California'],\n",
       "       [28754.33, 118546.05, 172795.67, 'California'],\n",
       "       [27892.92, 84710.77, 164470.71, 'Florida'],\n",
       "       [23640.93, 96189.63, 148001.11, 'California'],\n",
       "       [15505.73, 127382.3, 35534.17, 'New York'],\n",
       "       [22177.74, 154806.14, 28334.72, 'California'],\n",
       "       [1000.23, 124153.04, 1903.93, 'New York'],\n",
       "       [1315.46, 115816.21, 297114.46, 'Florida'],\n",
       "       [0.0, 135426.92, 0.0, 'California'],\n",
       "       [542.05, 51743.15, 0.0, 'New York'],\n",
       "       [0.0, 116983.8, 45173.06, 'California']], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd2ed577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependent variable matrix\n",
    "Y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db1c3784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([192261.83, 191792.06, 191050.39, 182901.99, 166187.94, 156991.12,\n",
       "       156122.51, 155752.6 , 152211.77, 149759.96, 146121.95, 144259.4 ,\n",
       "       141585.52, 134307.35, 132602.65, 129917.04, 126992.93, 125370.37,\n",
       "       124266.9 , 122776.86, 118474.03, 111313.02, 110352.25, 108733.99,\n",
       "       108552.04, 107404.34, 105733.54, 105008.31, 103282.38, 101004.64,\n",
       "        99937.59,  97483.56,  97427.84,  96778.92,  96712.8 ,  96479.51,\n",
       "        90708.19,  89949.14,  81229.06,  81005.76,  78239.91,  77798.83,\n",
       "        71498.49,  69758.98,  65200.33,  64926.08,  49490.75,  42559.73,\n",
       "        35673.41,  14681.4 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04d166ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical data\n",
    "\n",
    "#categorical variables - columns whose values are categories\n",
    "#we only want numbers in models, so we encode our text.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a34e4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 3] = labelencoder_X.fit_transform(X[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db3bffbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[165349.2, 136897.8, 471784.1, 2],\n",
       "       [162597.7, 151377.59, 443898.53, 0],\n",
       "       [153441.51, 101145.55, 407934.54, 1],\n",
       "       [144372.41, 118671.85, 383199.62, 2],\n",
       "       [142107.34, 91391.77, 366168.42, 1],\n",
       "       [131876.9, 99814.71, 362861.36, 2],\n",
       "       [134615.46, 147198.87, 127716.82, 0],\n",
       "       [130298.13, 145530.06, 323876.68, 1],\n",
       "       [120542.52, 148718.95, 311613.29, 2],\n",
       "       [123334.88, 108679.17, 304981.62, 0],\n",
       "       [101913.08, 110594.11, 229160.95, 1],\n",
       "       [100671.96, 91790.61, 249744.55, 0],\n",
       "       [93863.75, 127320.38, 249839.44, 1],\n",
       "       [91992.39, 135495.07, 252664.93, 0],\n",
       "       [119943.24, 156547.42, 256512.92, 1],\n",
       "       [114523.61, 122616.84, 261776.23, 2],\n",
       "       [78013.11, 121597.55, 264346.06, 0],\n",
       "       [94657.16, 145077.58, 282574.31, 2],\n",
       "       [91749.16, 114175.79, 294919.57, 1],\n",
       "       [86419.7, 153514.11, 0.0, 2],\n",
       "       [76253.86, 113867.3, 298664.47, 0],\n",
       "       [78389.47, 153773.43, 299737.29, 2],\n",
       "       [73994.56, 122782.75, 303319.26, 1],\n",
       "       [67532.53, 105751.03, 304768.73, 1],\n",
       "       [77044.01, 99281.34, 140574.81, 2],\n",
       "       [64664.71, 139553.16, 137962.62, 0],\n",
       "       [75328.87, 144135.98, 134050.07, 1],\n",
       "       [72107.6, 127864.55, 353183.81, 2],\n",
       "       [66051.52, 182645.56, 118148.2, 1],\n",
       "       [65605.48, 153032.06, 107138.38, 2],\n",
       "       [61994.48, 115641.28, 91131.24, 1],\n",
       "       [61136.38, 152701.92, 88218.23, 2],\n",
       "       [63408.86, 129219.61, 46085.25, 0],\n",
       "       [55493.95, 103057.49, 214634.81, 1],\n",
       "       [46426.07, 157693.92, 210797.67, 0],\n",
       "       [46014.02, 85047.44, 205517.64, 2],\n",
       "       [28663.76, 127056.21, 201126.82, 1],\n",
       "       [44069.95, 51283.14, 197029.42, 0],\n",
       "       [20229.59, 65947.93, 185265.1, 2],\n",
       "       [38558.51, 82982.09, 174999.3, 0],\n",
       "       [28754.33, 118546.05, 172795.67, 0],\n",
       "       [27892.92, 84710.77, 164470.71, 1],\n",
       "       [23640.93, 96189.63, 148001.11, 0],\n",
       "       [15505.73, 127382.3, 35534.17, 2],\n",
       "       [22177.74, 154806.14, 28334.72, 0],\n",
       "       [1000.23, 124153.04, 1903.93, 2],\n",
       "       [1315.46, 115816.21, 297114.46, 1],\n",
       "       [0.0, 135426.92, 0.0, 0],\n",
       "       [542.05, 51743.15, 0.0, 2],\n",
       "       [0.0, 116983.8, 45173.06, 0]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b45ad528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we cannot use the above encoding as this generates relationships where there is no relationship\n",
    "#therefore we use DUMMY ENCODING\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8105c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/54345667/onehotencoder-categorical-features-deprecated-how-to-transform-specific-column\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ct = ColumnTransformer([(\"State\", OneHotEncoder(), [3])], remainder = 'passthrough')\n",
    "X = ct.fit_transform(X)\n",
    "\n",
    "# onehotencoder = OneHotEncoder()\n",
    "# X = onehotencoder.fit_transform(X[:, 0]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06d78a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n",
       "       [1.0, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n",
       "       [0.0, 1.0, 0.0, 153441.51, 101145.55, 407934.54],\n",
       "       [0.0, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n",
       "       [0.0, 1.0, 0.0, 142107.34, 91391.77, 366168.42],\n",
       "       [0.0, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n",
       "       [1.0, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n",
       "       [0.0, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n",
       "       [0.0, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n",
       "       [1.0, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n",
       "       [0.0, 1.0, 0.0, 101913.08, 110594.11, 229160.95],\n",
       "       [1.0, 0.0, 0.0, 100671.96, 91790.61, 249744.55],\n",
       "       [0.0, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n",
       "       [1.0, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n",
       "       [0.0, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n",
       "       [0.0, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n",
       "       [1.0, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n",
       "       [0.0, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n",
       "       [0.0, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n",
       "       [0.0, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n",
       "       [1.0, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n",
       "       [0.0, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n",
       "       [0.0, 1.0, 0.0, 73994.56, 122782.75, 303319.26],\n",
       "       [0.0, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n",
       "       [0.0, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n",
       "       [1.0, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n",
       "       [0.0, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n",
       "       [0.0, 0.0, 1.0, 72107.6, 127864.55, 353183.81],\n",
       "       [0.0, 1.0, 0.0, 66051.52, 182645.56, 118148.2],\n",
       "       [0.0, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n",
       "       [0.0, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n",
       "       [0.0, 0.0, 1.0, 61136.38, 152701.92, 88218.23],\n",
       "       [1.0, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n",
       "       [0.0, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n",
       "       [1.0, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n",
       "       [0.0, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n",
       "       [0.0, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n",
       "       [1.0, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n",
       "       [0.0, 0.0, 1.0, 20229.59, 65947.93, 185265.1],\n",
       "       [1.0, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n",
       "       [1.0, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n",
       "       [0.0, 1.0, 0.0, 27892.92, 84710.77, 164470.71],\n",
       "       [1.0, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n",
       "       [0.0, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n",
       "       [1.0, 0.0, 0.0, 22177.74, 154806.14, 28334.72],\n",
       "       [0.0, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n",
       "       [0.0, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n",
       "       [1.0, 0.0, 0.0, 0.0, 135426.92, 0.0],\n",
       "       [0.0, 0.0, 1.0, 542.05, 51743.15, 0.0],\n",
       "       [1.0, 0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d73e7ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoiding the dummy variable trap\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c11f9b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 1.0, 165349.2, 136897.8, 471784.1],\n",
       "       [0.0, 0.0, 162597.7, 151377.59, 443898.53],\n",
       "       [1.0, 0.0, 153441.51, 101145.55, 407934.54],\n",
       "       [0.0, 1.0, 144372.41, 118671.85, 383199.62],\n",
       "       [1.0, 0.0, 142107.34, 91391.77, 366168.42],\n",
       "       [0.0, 1.0, 131876.9, 99814.71, 362861.36],\n",
       "       [0.0, 0.0, 134615.46, 147198.87, 127716.82],\n",
       "       [1.0, 0.0, 130298.13, 145530.06, 323876.68],\n",
       "       [0.0, 1.0, 120542.52, 148718.95, 311613.29],\n",
       "       [0.0, 0.0, 123334.88, 108679.17, 304981.62],\n",
       "       [1.0, 0.0, 101913.08, 110594.11, 229160.95],\n",
       "       [0.0, 0.0, 100671.96, 91790.61, 249744.55],\n",
       "       [1.0, 0.0, 93863.75, 127320.38, 249839.44],\n",
       "       [0.0, 0.0, 91992.39, 135495.07, 252664.93],\n",
       "       [1.0, 0.0, 119943.24, 156547.42, 256512.92],\n",
       "       [0.0, 1.0, 114523.61, 122616.84, 261776.23],\n",
       "       [0.0, 0.0, 78013.11, 121597.55, 264346.06],\n",
       "       [0.0, 1.0, 94657.16, 145077.58, 282574.31],\n",
       "       [1.0, 0.0, 91749.16, 114175.79, 294919.57],\n",
       "       [0.0, 1.0, 86419.7, 153514.11, 0.0],\n",
       "       [0.0, 0.0, 76253.86, 113867.3, 298664.47],\n",
       "       [0.0, 1.0, 78389.47, 153773.43, 299737.29],\n",
       "       [1.0, 0.0, 73994.56, 122782.75, 303319.26],\n",
       "       [1.0, 0.0, 67532.53, 105751.03, 304768.73],\n",
       "       [0.0, 1.0, 77044.01, 99281.34, 140574.81],\n",
       "       [0.0, 0.0, 64664.71, 139553.16, 137962.62],\n",
       "       [1.0, 0.0, 75328.87, 144135.98, 134050.07],\n",
       "       [0.0, 1.0, 72107.6, 127864.55, 353183.81],\n",
       "       [1.0, 0.0, 66051.52, 182645.56, 118148.2],\n",
       "       [0.0, 1.0, 65605.48, 153032.06, 107138.38],\n",
       "       [1.0, 0.0, 61994.48, 115641.28, 91131.24],\n",
       "       [0.0, 1.0, 61136.38, 152701.92, 88218.23],\n",
       "       [0.0, 0.0, 63408.86, 129219.61, 46085.25],\n",
       "       [1.0, 0.0, 55493.95, 103057.49, 214634.81],\n",
       "       [0.0, 0.0, 46426.07, 157693.92, 210797.67],\n",
       "       [0.0, 1.0, 46014.02, 85047.44, 205517.64],\n",
       "       [1.0, 0.0, 28663.76, 127056.21, 201126.82],\n",
       "       [0.0, 0.0, 44069.95, 51283.14, 197029.42],\n",
       "       [0.0, 1.0, 20229.59, 65947.93, 185265.1],\n",
       "       [0.0, 0.0, 38558.51, 82982.09, 174999.3],\n",
       "       [0.0, 0.0, 28754.33, 118546.05, 172795.67],\n",
       "       [1.0, 0.0, 27892.92, 84710.77, 164470.71],\n",
       "       [0.0, 0.0, 23640.93, 96189.63, 148001.11],\n",
       "       [0.0, 1.0, 15505.73, 127382.3, 35534.17],\n",
       "       [0.0, 0.0, 22177.74, 154806.14, 28334.72],\n",
       "       [0.0, 1.0, 1000.23, 124153.04, 1903.93],\n",
       "       [1.0, 0.0, 1315.46, 115816.21, 297114.46],\n",
       "       [0.0, 0.0, 0.0, 135426.92, 0.0],\n",
       "       [0.0, 1.0, 542.05, 51743.15, 0.0],\n",
       "       [0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77dfb589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into training and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "741b7004",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e40ddec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 55493.95, 103057.49, 214634.81],\n",
       "       [0.0, 1.0, 46014.02, 85047.44, 205517.64],\n",
       "       [1.0, 0.0, 75328.87, 144135.98, 134050.07],\n",
       "       [0.0, 0.0, 46426.07, 157693.92, 210797.67],\n",
       "       [1.0, 0.0, 91749.16, 114175.79, 294919.57],\n",
       "       [1.0, 0.0, 130298.13, 145530.06, 323876.68],\n",
       "       [1.0, 0.0, 119943.24, 156547.42, 256512.92],\n",
       "       [0.0, 1.0, 1000.23, 124153.04, 1903.93],\n",
       "       [0.0, 1.0, 542.05, 51743.15, 0.0],\n",
       "       [0.0, 1.0, 65605.48, 153032.06, 107138.38],\n",
       "       [0.0, 1.0, 114523.61, 122616.84, 261776.23],\n",
       "       [1.0, 0.0, 61994.48, 115641.28, 91131.24],\n",
       "       [0.0, 0.0, 63408.86, 129219.61, 46085.25],\n",
       "       [0.0, 0.0, 78013.11, 121597.55, 264346.06],\n",
       "       [0.0, 0.0, 23640.93, 96189.63, 148001.11],\n",
       "       [0.0, 0.0, 76253.86, 113867.3, 298664.47],\n",
       "       [0.0, 1.0, 15505.73, 127382.3, 35534.17],\n",
       "       [0.0, 1.0, 120542.52, 148718.95, 311613.29],\n",
       "       [0.0, 0.0, 91992.39, 135495.07, 252664.93],\n",
       "       [0.0, 0.0, 64664.71, 139553.16, 137962.62],\n",
       "       [0.0, 1.0, 131876.9, 99814.71, 362861.36],\n",
       "       [0.0, 1.0, 94657.16, 145077.58, 282574.31],\n",
       "       [0.0, 0.0, 28754.33, 118546.05, 172795.67],\n",
       "       [0.0, 0.0, 0.0, 116983.8, 45173.06],\n",
       "       [0.0, 0.0, 162597.7, 151377.59, 443898.53],\n",
       "       [1.0, 0.0, 93863.75, 127320.38, 249839.44],\n",
       "       [0.0, 0.0, 44069.95, 51283.14, 197029.42],\n",
       "       [0.0, 1.0, 77044.01, 99281.34, 140574.81],\n",
       "       [0.0, 0.0, 134615.46, 147198.87, 127716.82],\n",
       "       [1.0, 0.0, 67532.53, 105751.03, 304768.73],\n",
       "       [1.0, 0.0, 28663.76, 127056.21, 201126.82],\n",
       "       [0.0, 1.0, 78389.47, 153773.43, 299737.29],\n",
       "       [0.0, 1.0, 86419.7, 153514.11, 0.0],\n",
       "       [0.0, 0.0, 123334.88, 108679.17, 304981.62],\n",
       "       [0.0, 0.0, 38558.51, 82982.09, 174999.3],\n",
       "       [1.0, 0.0, 1315.46, 115816.21, 297114.46],\n",
       "       [0.0, 1.0, 144372.41, 118671.85, 383199.62],\n",
       "       [0.0, 1.0, 165349.2, 136897.8, 471784.1],\n",
       "       [0.0, 0.0, 0.0, 135426.92, 0.0],\n",
       "       [0.0, 0.0, 22177.74, 154806.14, 28334.72]], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bbb25b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 66051.52, 182645.56, 118148.2],\n",
       "       [0.0, 0.0, 100671.96, 91790.61, 249744.55],\n",
       "       [1.0, 0.0, 101913.08, 110594.11, 229160.95],\n",
       "       [1.0, 0.0, 27892.92, 84710.77, 164470.71],\n",
       "       [1.0, 0.0, 153441.51, 101145.55, 407934.54],\n",
       "       [0.0, 1.0, 72107.6, 127864.55, 353183.81],\n",
       "       [0.0, 1.0, 20229.59, 65947.93, 185265.1],\n",
       "       [0.0, 1.0, 61136.38, 152701.92, 88218.23],\n",
       "       [1.0, 0.0, 73994.56, 122782.75, 303319.26],\n",
       "       [1.0, 0.0, 142107.34, 91391.77, 366168.42]], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7d82afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 96778.92,  96479.51, 105733.54,  96712.8 , 124266.9 , 155752.6 ,\n",
       "       132602.65,  64926.08,  35673.41, 101004.64, 129917.04,  99937.59,\n",
       "        97427.84, 126992.93,  71498.49, 118474.03,  69758.98, 152211.77,\n",
       "       134307.35, 107404.34, 156991.12, 125370.37,  78239.91,  14681.4 ,\n",
       "       191792.06, 141585.52,  89949.14, 108552.04, 156122.51, 108733.99,\n",
       "        90708.19, 111313.02, 122776.86, 149759.96,  81005.76,  49490.75,\n",
       "       182901.99, 192261.83,  42559.73,  65200.33])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec8bd5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103282.38, 144259.4 , 146121.95,  77798.83, 191050.39, 105008.31,\n",
       "        81229.06,  97483.56, 110352.25, 166187.94])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60be1104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2 : Fitting the model onto training set\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc96874d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10ebecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 3 : Predicting the Test Results Values\n",
    "\n",
    "#creating predictions vector\n",
    "y_pred = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fadb056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103015.20159797, 132582.27760815, 132447.73845175,  71976.09851258,\n",
       "       178537.48221055, 116161.24230165,  67851.69209676,  98791.73374688,\n",
       "       113969.43533012, 167921.0656955 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65e2b7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103282.38, 144259.4 , 146121.95,  77798.83, 191050.39, 105008.31,\n",
       "        81229.06,  97483.56, 110352.25, 166187.94])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9764ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple linear dependency between independent and dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73757d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 4 : Building the optimal model using Backward Elimination\n",
    "#removing the variables having least impact, keeping the variables which are statistically significant\n",
    "\n",
    "# import statsmodels.formula.api as sm\n",
    "\n",
    "#https://stackoverflow.com/questions/57906297/from-formula-missing-2-required-positional-arguments-formula-and-data\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa934e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 of backward elimination - select significance level, SL=0.05 or 5%\n",
    "\n",
    "#adding column of 1's as x0 = 1 for the equation\n",
    "\n",
    "X = np.append(arr = np.ones((50, 1)).astype(int), values = X, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ade2666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n",
       "       [1, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n",
       "       [1, 1.0, 0.0, 153441.51, 101145.55, 407934.54],\n",
       "       [1, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n",
       "       [1, 1.0, 0.0, 142107.34, 91391.77, 366168.42],\n",
       "       [1, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n",
       "       [1, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n",
       "       [1, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n",
       "       [1, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n",
       "       [1, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n",
       "       [1, 1.0, 0.0, 101913.08, 110594.11, 229160.95],\n",
       "       [1, 0.0, 0.0, 100671.96, 91790.61, 249744.55],\n",
       "       [1, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n",
       "       [1, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n",
       "       [1, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n",
       "       [1, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n",
       "       [1, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n",
       "       [1, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n",
       "       [1, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n",
       "       [1, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n",
       "       [1, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n",
       "       [1, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n",
       "       [1, 1.0, 0.0, 73994.56, 122782.75, 303319.26],\n",
       "       [1, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n",
       "       [1, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n",
       "       [1, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n",
       "       [1, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n",
       "       [1, 0.0, 1.0, 72107.6, 127864.55, 353183.81],\n",
       "       [1, 1.0, 0.0, 66051.52, 182645.56, 118148.2],\n",
       "       [1, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n",
       "       [1, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n",
       "       [1, 0.0, 1.0, 61136.38, 152701.92, 88218.23],\n",
       "       [1, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n",
       "       [1, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n",
       "       [1, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n",
       "       [1, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n",
       "       [1, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n",
       "       [1, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n",
       "       [1, 0.0, 1.0, 20229.59, 65947.93, 185265.1],\n",
       "       [1, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n",
       "       [1, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n",
       "       [1, 1.0, 0.0, 27892.92, 84710.77, 164470.71],\n",
       "       [1, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n",
       "       [1, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n",
       "       [1, 0.0, 0.0, 22177.74, 154806.14, 28334.72],\n",
       "       [1, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n",
       "       [1, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n",
       "       [1, 0.0, 0.0, 0.0, 135426.92, 0.0],\n",
       "       [1, 0.0, 1.0, 542.05, 51743.15, 0.0],\n",
       "       [1, 0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e083a671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending X matrix to x_opt\n",
    "x_opt = X[:, [0, 1, 2, 3, 4, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a06de0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000000, 0.000000, 1.000000, 165349.200000, 136897.800000,\n",
       "        471784.100000],\n",
       "       [1.000000, 0.000000, 0.000000, 162597.700000, 151377.590000,\n",
       "        443898.530000],\n",
       "       [1.000000, 1.000000, 0.000000, 153441.510000, 101145.550000,\n",
       "        407934.540000],\n",
       "       [1.000000, 0.000000, 1.000000, 144372.410000, 118671.850000,\n",
       "        383199.620000],\n",
       "       [1.000000, 1.000000, 0.000000, 142107.340000, 91391.770000,\n",
       "        366168.420000],\n",
       "       [1.000000, 0.000000, 1.000000, 131876.900000, 99814.710000,\n",
       "        362861.360000],\n",
       "       [1.000000, 0.000000, 0.000000, 134615.460000, 147198.870000,\n",
       "        127716.820000],\n",
       "       [1.000000, 1.000000, 0.000000, 130298.130000, 145530.060000,\n",
       "        323876.680000],\n",
       "       [1.000000, 0.000000, 1.000000, 120542.520000, 148718.950000,\n",
       "        311613.290000],\n",
       "       [1.000000, 0.000000, 0.000000, 123334.880000, 108679.170000,\n",
       "        304981.620000],\n",
       "       [1.000000, 1.000000, 0.000000, 101913.080000, 110594.110000,\n",
       "        229160.950000],\n",
       "       [1.000000, 0.000000, 0.000000, 100671.960000, 91790.610000,\n",
       "        249744.550000],\n",
       "       [1.000000, 1.000000, 0.000000, 93863.750000, 127320.380000,\n",
       "        249839.440000],\n",
       "       [1.000000, 0.000000, 0.000000, 91992.390000, 135495.070000,\n",
       "        252664.930000],\n",
       "       [1.000000, 1.000000, 0.000000, 119943.240000, 156547.420000,\n",
       "        256512.920000],\n",
       "       [1.000000, 0.000000, 1.000000, 114523.610000, 122616.840000,\n",
       "        261776.230000],\n",
       "       [1.000000, 0.000000, 0.000000, 78013.110000, 121597.550000,\n",
       "        264346.060000],\n",
       "       [1.000000, 0.000000, 1.000000, 94657.160000, 145077.580000,\n",
       "        282574.310000],\n",
       "       [1.000000, 1.000000, 0.000000, 91749.160000, 114175.790000,\n",
       "        294919.570000],\n",
       "       [1.000000, 0.000000, 1.000000, 86419.700000, 153514.110000,\n",
       "        0.000000],\n",
       "       [1.000000, 0.000000, 0.000000, 76253.860000, 113867.300000,\n",
       "        298664.470000],\n",
       "       [1.000000, 0.000000, 1.000000, 78389.470000, 153773.430000,\n",
       "        299737.290000],\n",
       "       [1.000000, 1.000000, 0.000000, 73994.560000, 122782.750000,\n",
       "        303319.260000],\n",
       "       [1.000000, 1.000000, 0.000000, 67532.530000, 105751.030000,\n",
       "        304768.730000],\n",
       "       [1.000000, 0.000000, 1.000000, 77044.010000, 99281.340000,\n",
       "        140574.810000],\n",
       "       [1.000000, 0.000000, 0.000000, 64664.710000, 139553.160000,\n",
       "        137962.620000],\n",
       "       [1.000000, 1.000000, 0.000000, 75328.870000, 144135.980000,\n",
       "        134050.070000],\n",
       "       [1.000000, 0.000000, 1.000000, 72107.600000, 127864.550000,\n",
       "        353183.810000],\n",
       "       [1.000000, 1.000000, 0.000000, 66051.520000, 182645.560000,\n",
       "        118148.200000],\n",
       "       [1.000000, 0.000000, 1.000000, 65605.480000, 153032.060000,\n",
       "        107138.380000],\n",
       "       [1.000000, 1.000000, 0.000000, 61994.480000, 115641.280000,\n",
       "        91131.240000],\n",
       "       [1.000000, 0.000000, 1.000000, 61136.380000, 152701.920000,\n",
       "        88218.230000],\n",
       "       [1.000000, 0.000000, 0.000000, 63408.860000, 129219.610000,\n",
       "        46085.250000],\n",
       "       [1.000000, 1.000000, 0.000000, 55493.950000, 103057.490000,\n",
       "        214634.810000],\n",
       "       [1.000000, 0.000000, 0.000000, 46426.070000, 157693.920000,\n",
       "        210797.670000],\n",
       "       [1.000000, 0.000000, 1.000000, 46014.020000, 85047.440000,\n",
       "        205517.640000],\n",
       "       [1.000000, 1.000000, 0.000000, 28663.760000, 127056.210000,\n",
       "        201126.820000],\n",
       "       [1.000000, 0.000000, 0.000000, 44069.950000, 51283.140000,\n",
       "        197029.420000],\n",
       "       [1.000000, 0.000000, 1.000000, 20229.590000, 65947.930000,\n",
       "        185265.100000],\n",
       "       [1.000000, 0.000000, 0.000000, 38558.510000, 82982.090000,\n",
       "        174999.300000],\n",
       "       [1.000000, 0.000000, 0.000000, 28754.330000, 118546.050000,\n",
       "        172795.670000],\n",
       "       [1.000000, 1.000000, 0.000000, 27892.920000, 84710.770000,\n",
       "        164470.710000],\n",
       "       [1.000000, 0.000000, 0.000000, 23640.930000, 96189.630000,\n",
       "        148001.110000],\n",
       "       [1.000000, 0.000000, 1.000000, 15505.730000, 127382.300000,\n",
       "        35534.170000],\n",
       "       [1.000000, 0.000000, 0.000000, 22177.740000, 154806.140000,\n",
       "        28334.720000],\n",
       "       [1.000000, 0.000000, 1.000000, 1000.230000, 124153.040000,\n",
       "        1903.930000],\n",
       "       [1.000000, 1.000000, 0.000000, 1315.460000, 115816.210000,\n",
       "        297114.460000],\n",
       "       [1.000000, 0.000000, 0.000000, 0.000000, 135426.920000, 0.000000],\n",
       "       [1.000000, 0.000000, 1.000000, 542.050000, 51743.150000, 0.000000],\n",
       "       [1.000000, 0.000000, 0.000000, 0.000000, 116983.800000,\n",
       "        45173.060000]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changing the datatype of x_opt to be same as Y\n",
    "x_opt = x_opt.astype(float)\n",
    "\n",
    "#changing printing options of numpy from scientific notations to standard form\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "x_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb3f4e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2 of backward elimination - fitting all the predictors to our regressor\n",
    "\n",
    "#new regressor of new library as library is new so we need to create new object\n",
    "\n",
    "regressor_OLS = sm.OLS(endog = Y, exog = x_opt).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b237aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   169.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Sep 2022</td> <th>  Prob (F-statistic):</th> <td>1.34e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>06:52:39</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>   1074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.013e+04</td> <td> 6884.820</td> <td>    7.281</td> <td> 0.000</td> <td> 3.62e+04</td> <td>  6.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  198.7888</td> <td> 3371.007</td> <td>    0.059</td> <td> 0.953</td> <td>-6595.030</td> <td> 6992.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  -41.8870</td> <td> 3256.039</td> <td>   -0.013</td> <td> 0.990</td> <td>-6604.003</td> <td> 6520.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.369</td> <td> 0.000</td> <td>    0.712</td> <td>    0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.517</td> <td> 0.608</td> <td>   -0.132</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.574</td> <td> 0.123</td> <td>   -0.008</td> <td>    0.062</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.782</td> <th>  Durbin-Watson:     </th> <td>   1.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.41e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.572</td> <th>  Cond. No.          </th> <td>1.45e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.45e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     169.9\n",
       "Date:                Wed, 14 Sep 2022   Prob (F-statistic):           1.34e-27\n",
       "Time:                        06:52:39   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1063.\n",
       "Df Residuals:                      44   BIC:                             1074.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.013e+04   6884.820      7.281      0.000    3.62e+04     6.4e+04\n",
       "x1           198.7888   3371.007      0.059      0.953   -6595.030    6992.607\n",
       "x2           -41.8870   3256.039     -0.013      0.990   -6604.003    6520.229\n",
       "x3             0.8060      0.046     17.369      0.000       0.712       0.900\n",
       "x4            -0.0270      0.052     -0.517      0.608      -0.132       0.078\n",
       "x5             0.0270      0.017      1.574      0.123      -0.008       0.062\n",
       "==============================================================================\n",
       "Omnibus:                       14.782   Durbin-Watson:                   1.283\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.266\n",
       "Skew:                          -0.948   Prob(JB):                     2.41e-05\n",
       "Kurtosis:                       5.572   Cond. No.                     1.45e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.45e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 3 of backward elimination - if P-value > SL, remove the predictor, if P-value < SL then our model is ready.\n",
    "\n",
    "#finding predictor with highest p-values\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "195bae33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Sep 2022</td> <th>  Prob (F-statistic):</th> <td>8.49e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>06:59:24</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1061.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1070.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.011e+04</td> <td> 6647.870</td> <td>    7.537</td> <td> 0.000</td> <td> 3.67e+04</td> <td> 6.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  220.1585</td> <td> 2900.536</td> <td>    0.076</td> <td> 0.940</td> <td>-5621.821</td> <td> 6062.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.606</td> <td> 0.000</td> <td>    0.714</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.523</td> <td> 0.604</td> <td>   -0.131</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.592</td> <td> 0.118</td> <td>   -0.007</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.758</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.53e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.563</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     217.2\n",
       "Date:                Wed, 14 Sep 2022   Prob (F-statistic):           8.49e-29\n",
       "Time:                        06:59:24   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1061.\n",
       "Df Residuals:                      45   BIC:                             1070.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.011e+04   6647.870      7.537      0.000    3.67e+04    6.35e+04\n",
       "x1           220.1585   2900.536      0.076      0.940   -5621.821    6062.138\n",
       "x2             0.8060      0.046     17.606      0.000       0.714       0.898\n",
       "x3            -0.0270      0.052     -0.523      0.604      -0.131       0.077\n",
       "x4             0.0270      0.017      1.592      0.118      -0.007       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.758   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.172\n",
       "Skew:                          -0.948   Prob(JB):                     2.53e-05\n",
       "Kurtosis:                       5.563   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 4 of backward elimination - remove the predictor with p value > 0.05\n",
    "#therefore removing x2, index 2\n",
    "\n",
    "x_opt = X[:, [0, 1, 3, 4, 5]]\n",
    "\n",
    "#changing the datatype of x_opt to be same as Y\n",
    "x_opt = x_opt.astype(float)\n",
    "\n",
    "regressor_OLS = sm.OLS(endog = Y, exog = x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8ffd3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Sep 2022</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:04:14</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.012e+04</td> <td> 6572.353</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04</td> <td> 6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     296.0\n",
       "Date:                Wed, 14 Sep 2022   Prob (F-statistic):           4.53e-30\n",
       "Time:                        07:04:14   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      46   BIC:                             1066.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\n",
       "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
       "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
       "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
       "==============================================================================\n",
       "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
       "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
       "Kurtosis:                       5.586   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#therefore removing x1, index 1\n",
    "\n",
    "x_opt = X[:, [0, 3, 4, 5]]\n",
    "\n",
    "#changing the datatype of x_opt to be same as Y\n",
    "x_opt = x_opt.astype(float)\n",
    "\n",
    "regressor_OLS = sm.OLS(endog = Y, exog = x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63969fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Sep 2022</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:05:49</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Wed, 14 Sep 2022   Prob (F-statistic):           2.16e-31\n",
       "Time:                        07:05:49   Log-Likelihood:                -525.54\n",
       "No. Observations:                  50   AIC:                             1057.\n",
       "Df Residuals:                      47   BIC:                             1063.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
       "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
       "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#therefore removing x2, index 4\n",
    "\n",
    "x_opt = X[:, [0, 3, 5]]\n",
    "\n",
    "#changing the datatype of x_opt to be same as Y\n",
    "x_opt = x_opt.astype(float)\n",
    "\n",
    "regressor_OLS = sm.OLS(endog = Y, exog = x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "061b1fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   849.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Sep 2022</td> <th>  Prob (F-statistic):</th> <td>3.50e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:11:00</td>     <th>  Log-Likelihood:    </th> <td> -527.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.903e+04</td> <td> 2537.897</td> <td>   19.320</td> <td> 0.000</td> <td> 4.39e+04</td> <td> 5.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8543</td> <td>    0.029</td> <td>   29.151</td> <td> 0.000</td> <td>    0.795</td> <td>    0.913</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.727</td> <th>  Durbin-Watson:     </th> <td>   1.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.911</td> <th>  Prob(JB):          </th> <td>9.44e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.361</td> <th>  Cond. No.          </th> <td>1.65e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.65e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.947\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     849.8\n",
       "Date:                Wed, 14 Sep 2022   Prob (F-statistic):           3.50e-32\n",
       "Time:                        07:11:00   Log-Likelihood:                -527.44\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      48   BIC:                             1063.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.903e+04   2537.897     19.320      0.000    4.39e+04    5.41e+04\n",
       "x1             0.8543      0.029     29.151      0.000       0.795       0.913\n",
       "==============================================================================\n",
       "Omnibus:                       13.727   Durbin-Watson:                   1.116\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.536\n",
       "Skew:                          -0.911   Prob(JB):                     9.44e-05\n",
       "Kurtosis:                       5.361   Cond. No.                     1.65e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.65e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#therefore removing x2, index 5\n",
    "\n",
    "x_opt = X[:, [0, 3]]\n",
    "\n",
    "#changing the datatype of x_opt to be same as Y\n",
    "x_opt = x_opt.astype(float)\n",
    "\n",
    "regressor_OLS = sm.OLS(endog = Y, exog = x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467db9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 5 of backward elimination - as no P-value > 0.05, our model is ready"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
